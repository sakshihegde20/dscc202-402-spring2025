{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc85e8e1-c161-4bbb-b821-06a6fecaab06",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "https://www.unofficialgoogledatascience.com/2016/10/practical-advice-for-analysis-of-large.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3886af8-e018-4ee5-8339-e60862b35a25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "although the mean and standard deviation may suggest a unimodal, symmetric distribution, a histogram reveals two distinct peaks—critical information missed by summary stats alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bcc99bee-f671-422d-8f9d-a1ef2196e210",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Know Your Data"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Generate a bimodal dataset\n",
    "data = np.concatenate([np.random.normal(5, 1, 1000), np.random.normal(15, 1, 1000)])\n",
    "df = pd.DataFrame({'value': data})\n",
    "\n",
    "# Summary statistics\n",
    "print(df.describe())\n",
    "\n",
    "# Histogram\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.histplot(df['value'], kde=True, bins=30)\n",
    "plt.title(\"Histogram with KDE - Bimodal Distribution\")\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "714b22df-65b8-4a24-8a1f-d69ed185f469",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This boxplot helps identify extreme values. Rather than immediately removing them, review the data source or context—outliers may signal important anomalies like sensor errors or exceptional behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4744050a-d044-4b90-b7a6-1ff1d6b3d2a0",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Outliers?"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Simulate a dataset with outliers\n",
    "data = np.append(np.random.normal(50, 10, 100), [5, 150])\n",
    "df = pd.DataFrame({'value': data})\n",
    "\n",
    "# Calculate IQR and determine outliers\n",
    "Q1 = df['value'].quantile(0.25)\n",
    "Q3 = df['value'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Flag outliers\n",
    "df['is_outlier'] = (df['value'] < lower_bound) | (df['value'] > upper_bound)\n",
    "\n",
    "# Visualize with boxplot\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.boxplot(x=df['value'])\n",
    "plt.title(\"Boxplot with Outliers Highlighted\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e20fdfb6-f2fb-48c8-b938-65f32d9eaceb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This example illustrates how to report not only a point estimate (the mean) but also the uncertainty around it—helping stakeholders understand the precision of your analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a072a70f-4f61-4a6c-9e61-3b39e32b62fa",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Confidence"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Sample data\n",
    "np.random.seed(42)\n",
    "data = np.random.normal(loc=100, scale=15, size=200)\n",
    "\n",
    "# Sample mean and standard error\n",
    "mean = np.mean(data)\n",
    "sem = stats.sem(data)\n",
    "\n",
    "# 95% confidence interval\n",
    "confidence = 0.95\n",
    "margin_of_error = sem * stats.t.ppf((1 + confidence) / 2., len(data)-1)\n",
    "ci_lower = mean - margin_of_error\n",
    "ci_upper = mean + margin_of_error\n",
    "\n",
    "print(f\"Mean: {mean:.2f}\")\n",
    "print(f\"95% Confidence Interval: ({ci_lower:.2f}, {ci_upper:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aae16f22-aa92-4cc3-a8c0-d05641438f6e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This example highlights how looking directly at raw values can reveal issues like invalid timestamps or incorrect data types that could silently break your downstream logic if unchecked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86ce39f0-4acc-44e5-96ce-e2c5a8111d9a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Examine Raw Data"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load sample data (simulate log data)\n",
    "data = {\n",
    "    'timestamp': ['2024-01-01 12:00:00', '2024-01-01 12:01:00', 'not_a_timestamp'],\n",
    "    'event': ['login', 'click', None],\n",
    "    'user_id': [123, 124, 'abc']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display raw data\n",
    "print(\"Sample Raw Data:\")\n",
    "print(df.head())\n",
    "\n",
    "# Check for parsing issues\n",
    "print(\"Data Types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Attempt to convert timestamp\n",
    "df['timestamp_converted'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
    "print(\"With Converted Timestamps:\")\n",
    "print(df[['timestamp', 'timestamp_converted']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9ef10c7-68b0-44a7-8343-fb27e58ecbc9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This simple segmentation reveals differences in user behavior between mobile and desktop platforms—insights that might be hidden in aggregate statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f8c942d-a792-4f8e-bbbe-ff5bc8d65833",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Slice"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Simulated user engagement data\n",
    "data = {\n",
    "    'device_type': ['mobile'] * 50 + ['desktop'] * 50,\n",
    "    'session_duration': list(np.random.normal(5, 1.5, 50)) + list(np.random.normal(8, 2, 50))\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Compare distributions by device type\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.boxplot(x='device_type', y='session_duration', data=df)\n",
    "plt.title(\"Session Duration by Device Type\")\n",
    "plt.ylabel(\"Minutes\")\n",
    "plt.xlabel(\"Device Type\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "073e7f7b-d8f8-40cd-90bc-12dfd4a41d75",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Objective:**\n",
    "To verify whether all expected data is being correctly logged—this is crucial before relying on the dataset for analysis.\n",
    "\n",
    "**Step-by-step Breakdown:**\n",
    "**1. Simulate Log Data**\n",
    "\n",
    "    `log_data = pd.DataFrame({\n",
    "        'event_type': ['click', 'view', 'click', 'hover', 'scroll'],\n",
    "        'timestamp': pd.date_range(\"2024-01-01\", periods=5, freq='T'),\n",
    "        'element_id': ['btn-1', 'img-2', 'btn-2', None, 'div-3']\n",
    "    })`\n",
    "\n",
    "Creates a small DataFrame mimicking logging events on a website. Each row represents a user interaction with metadata:\n",
    "\n",
    "- event_type: the type of user action\n",
    "- timestamp: when it occurred\n",
    "- element_id: the webpage element interacted with\n",
    "\n",
    "**2. Check for Missing Data**\n",
    "\n",
    "    `missing_elements = log_data[log_data['element_id'].isnull()]`\n",
    "\n",
    "This filters rows where element_id is None (i.e., not recorded). These might indicate a bug in how the frontend tags or logs interactions.\n",
    "\n",
    "**3. Validate Event Coverage**\n",
    "\n",
    "    `expected_events = {'click', 'view', 'scroll', 'hover'}\n",
    "    logged_events = set(log_data['event_type'].unique())\n",
    "    missing_events = expected_events - logged_events`\n",
    "\n",
    "Here, you define the events you expect to find (expected_events) and compare that with what’s actually in the log (logged_events). Any difference means something might be wrong (e.g., a misconfigured tracker not logging one type of event).\n",
    "\n",
    "**Why It Matters:**\n",
    "If element_id is missing, you can’t trace user actions accurately.\n",
    "\n",
    "If some events like hover or scroll are never logged, analyses on those behaviors will be misleading or incomplete.\n",
    "\n",
    "This kind of basic validation is easy to overlook but critical for trustworthy insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "965ebff9-67d6-4069-8fd6-dfc75bda69d8",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Validate Data Collection"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Simulated log data\n",
    "log_data = pd.DataFrame({\n",
    "    'event_type': ['click', 'view', 'click', 'hover', 'scroll'],\n",
    "    'timestamp': pd.date_range(\"2024-01-01\", periods=5, freq='T'),\n",
    "    'element_id': ['btn-1', 'img-2', 'btn-2', None, 'div-3']\n",
    "})\n",
    "\n",
    "# Check for missing critical data\n",
    "missing_elements = log_data[log_data['element_id'].isnull()]\n",
    "print(\"Missing element IDs:\")\n",
    "print(missing_elements)\n",
    "\n",
    "# Check that all expected event types are being logged\n",
    "expected_events = {'click', 'view', 'scroll', 'hover'}\n",
    "logged_events = set(log_data['event_type'].unique())\n",
    "missing_events = expected_events - logged_events\n",
    "print(\"Missing expected event types:\", missing_events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3a4b968-1572-459a-a664-06e53b59fd31",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Be Quick...refine later"
    }
   },
   "source": [
    "Example:\n",
    "Suppose you're building a dashboard to monitor customer churn. Instead of perfecting data cleaning first, build a quick prototype that connects raw data to key metrics:\n",
    "This prototype quickly reveals that two customers are likely to churn. Based on stakeholder feedback, you can refine the threshold, add visualizations, and later optimize performance or automate the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7aeca2aa-980d-4e87-8652-f286fa672b32",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Simulated data\n",
    "raw_data = pd.DataFrame({\n",
    "    'customer_id': [1, 2, 3, 4, 5],\n",
    "    'is_active': [1, 0, 1, 1, 0],\n",
    "    'last_login_days_ago': [5, 60, 15, 3, 90]\n",
    "})\n",
    "\n",
    "# Prototype churn rule\n",
    "raw_data['likely_churn'] = raw_data['last_login_days_ago'] > 30\n",
    "\n",
    "# Simple summary\n",
    "summary = raw_data.groupby('likely_churn')['customer_id'].count()\n",
    "print(\"Churn Summary:\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69ccb6d2-95c0-4628-b913-bd59cb9e1a4f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Example**:\n",
    "Imagine you run an A/B test on a website feature and find a statistically significant improvement in user engagement:\n",
    "The result may be statistically significant (e.g., p < 0.05), but a 0.5 minute increase in average session duration may not justify development cost or user experience risk. You must contextualize significance with business impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51b67ae4-2ad1-4471-bd23-587bd7966a99",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Simulate engagement durations (in minutes)\n",
    "a = np.random.normal(10.0, 2.0, 1000)  # group A (control)\n",
    "b = np.random.normal(10.5, 2.0, 1000)  # group B (treatment)\n",
    "\n",
    "# t-test for significance\n",
    "t_stat, p_val = stats.ttest_ind(a, b)\n",
    "print(f\"p-value: {p_val:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a14c809-0f58-4c65-a76b-b7a80b5f09ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This example shows how a subtle but meaningful shift in a key metric can be easily spotted with time series monitoring. It's a valuable technique for catching unintended side effects after deployments or system changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ead71f20-fad0-41ac-9bff-80d373998b16",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Monitor over time"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Simulate time series data\n",
    "dates = pd.date_range(start='2024-01-01', periods=100, freq='D')\n",
    "data = np.random.normal(loc=100, scale=5, size=100)\n",
    "data[60:] += 10  # simulate a sudden shift\n",
    "df = pd.DataFrame({'date': dates, 'metric': data})\n",
    "\n",
    "# Plot time series\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(df['date'], df['metric'], marker='o', linestyle='-')\n",
    "plt.axvline(df['date'].iloc[60], color='red', linestyle='--', label='Change Point')\n",
    "plt.title(\"Metric Over Time with Simulated Shift\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Metric Value\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Analyzing Big Datasets",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
